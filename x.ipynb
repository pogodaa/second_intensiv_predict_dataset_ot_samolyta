{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1\n",
    "# Импортирование библиотек\n",
    "import pandas as pd\n",
    "import os, warnings, joblib\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve, classification_report\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# Смотрим исходные данные\n",
    "train = pd.read_csv(\"df/train.csv\", low_memory=False)\n",
    "valid = pd.read_csv(\"df/valid.csv\", low_memory=False)\n",
    "\n",
    "arr = [train, valid]\n",
    "names_df = ['train', 'valid']\n",
    "\n",
    "# Анализ данных\n",
    "def analyze_data(df):\n",
    "    print(df.describe())\n",
    "    sns.countplot(x='target', data=df)\n",
    "    plt.title('Distribution of Target Variable')\n",
    "    plt.show()\n",
    "\n",
    "for i, elem in enumerate(arr):\n",
    "    print(f'Анализ данных для {names_df[i]}:')\n",
    "    analyze_data(elem)\n",
    "\n",
    "# Остальной код...\n",
    "\n",
    "# Модель RandomForestClassifier\n",
    "X = train_updt.drop(columns=['client_id', 'target', 'report_date'])\n",
    "y = train_updt['target']\n",
    "\n",
    "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_features = X.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "X[categorical_features] = X[categorical_features].astype(str)\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(random_state=42, n_estimators=100, class_weight='balanced'))\n",
    "])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "test_preds = model.predict(X_test)\n",
    "test_preds_proba = model.predict_proba(X_test)[:, 1]\n",
    "test_score = roc_auc_score(y_test, test_preds_proba)\n",
    "\n",
    "print('Test')\n",
    "print(f\"Accuracy: {accuracy_score(y_test, test_preds):.4f}\")\n",
    "print(f\"ROC-AUC: {test_score:.4f}\")\n",
    "print(classification_report(y_test, test_preds))\n",
    "\n",
    "#########################################################################################\n",
    "perenos_()\n",
    "\n",
    "X_valid = valid_updt.drop(columns=['client_id', 'target', 'report_date'], errors='ignore')\n",
    "y_valid = valid_updt['target']\n",
    "X_valid[categorical_features] = X_valid[categorical_features].astype(str)\n",
    "\n",
    "valid_preds = model.predict(X_valid)\n",
    "valid_preds_proba = model.predict_proba(X_valid)[:, 1]\n",
    "valid_score = roc_auc_score(y_valid, valid_preds_proba)\n",
    "\n",
    "print('Valid')\n",
    "print(f\"Accuracy: {accuracy_score(y_valid, valid_preds):.4f}\")\n",
    "print(f\"ROC-AUC: {valid_score:.4f}\")\n",
    "print(classification_report(y_valid, valid_preds))\n",
    "\n",
    "# Модель XGBoost\n",
    "# Т.к. XGBoost не может обрабатывать столбцы типа object (строковые) без предварительной обработки. \n",
    "# Сделаем предварительные обработки\n",
    "\n",
    "# Использование fit_transform для обучающего набора = обучаете \n",
    "X_train_transformed = preprocessor.fit_transform(X_train)\n",
    "# transform для тестового и валидационного наборов = применяете\n",
    "X_test_transformed = p\n",
    "\n",
    "reprocessor.transform(X_test)\n",
    "X_valid_transformed = preprocessor.transform(X_valid)\n",
    "\n",
    "# Создание и обучение модели XGBoost\n",
    "model_xgb = XGBClassifier(scale_pos_weight=len(y_train) / sum(y_train == 1),\n",
    "                      random_state=42,\n",
    "                      eval_metric='logloss',\n",
    "                      max_depth=30,\n",
    "                      n_estimators=500,\n",
    "                      learning_rate=0.1)\n",
    "\n",
    "model_xgb.fit(X_train_transformed, y_train)\n",
    "\n",
    "# Кросс-валидация\n",
    "cv_scores_xgb = cross_val_score(model_xgb, X_train_transformed, y_train, cv=kf, scoring='roc_auc')\n",
    "print(f'Кросс-валидация ROC-AUC XGBoost: {cv_scores_xgb.mean():.4f} ± {cv_scores_xgb.std():.4f}')\n",
    "\n",
    "test_preds_xgb = model_xgb.predict(X_test_transformed)\n",
    "test_preds_proba_xgb = model_xgb.predict_proba(X_test_transformed)[:, 1]\n",
    "test_score_xgb = roc_auc_score(y_test, test_preds_proba_xgb)\n",
    "\n",
    "print('Test XGBoost')\n",
    "print(f\"Accuracy: {accuracy_score(y_test, test_preds_xgb):.4f}\")\n",
    "print(f\"ROC-AUC: {test_score_xgb:.4f}\")\n",
    "print(classification_report(y_test, test_preds_xgb))\n",
    "\n",
    "#########################################################################################\n",
    "perenos_()\n",
    "\n",
    "valid_preds_xgb = model_xgb.predict(X_valid_transformed)\n",
    "valid_preds_proba_xgb = model_xgb.predict_proba(X_valid_transformed)[:, 1]\n",
    "valid_score_xgb = roc_auc_score(y_valid, valid_preds_proba_xgb)\n",
    "\n",
    "print('Valid XGBoost')\n",
    "print(f\"Accuracy: {accuracy_score(y_valid, valid_preds_xgb):.4f}\")\n",
    "print(f\"ROC-AUC: {valid_score_xgb:.4f}\")\n",
    "print(classification_report(y_valid, valid_preds_xgb))\n",
    "\n",
    "# Модель LightGBM\n",
    "# Игнорирование FutureWarning\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# Установка переменной окружения\n",
    "os.environ[\"LOKY_MAX_CPU_COUNT\"] = \"4\"\n",
    "\n",
    "lgb_model = LGBMClassifier(boosting_type='gbdt',\n",
    "    objective='binary',\n",
    "    class_weight='balanced',\n",
    "    learning_rate=0.01, n_estimators=500, num_leaves=20, min_child_samples=30, random_state=42)\n",
    "\n",
    "lgb_model.fit(X_train_transformed, y_train)\n",
    "\n",
    "# Кросс-валидация\n",
    "cv_scores_lgb = cross_val_score(lgb_model, X_train_transformed, y_train, cv=kf, scoring='roc_auc')\n",
    "print(f'Кросс-валидация ROC-AUC LightGBM: {cv_scores_lgb.mean():.4f} ± {cv_scores_lgb.std():.4f}')\n",
    "\n",
    "test_preds_lgb = lgb_model.predict(X_test_transformed)\n",
    "test_preds_proba_lgb = lgb_model.predict_proba(X_test_transformed)[:, 1]\n",
    "test_score_lgb = roc_auc_score(y_test, test_preds_proba_lgb)\n",
    "\n",
    "print('\\nTest LightGBM')\n",
    "print(f\"Accuracy: {accuracy_score(y_test, test_preds_lgb):.4f}\")\n",
    "print(f\"ROC-AUC: {test_score_lgb:.4f}\")\n",
    "print(classification_report(y_test, test_preds_lgb))\n",
    "\n",
    "#########################################################################################\n",
    "perenos_()\n",
    "\n",
    "valid_preds_lgb = lgb_model.predict(X_valid_transformed)\n",
    "valid_preds_proba_lgb = lgb_model.predict_proba(X_valid_transformed)[:, 1]\n",
    "valid_score_lgb = roc_auc_score(y_valid, valid_preds_proba_lgb)\n",
    "\n",
    "print('Valid LightGBM')\n",
    "print(f\"Accuracy: {accuracy_score(y_valid, valid_preds_lgb):.4f}\")\n",
    "print(f\"ROC-AUC: {valid_score_lgb:.4f}\")\n",
    "print(classification_report(y_valid, valid_preds_lgb))\n",
    "```\n",
    "\n",
    "### Добавленные элементы:\n",
    "1. **Анализ данных**: Функция `analyze_data` для отображения описательной статистики и распределения целевой переменной.\n",
    "2. **Метрики**: Использование `classification_report` для более детальной оценки моделей.\n",
    "3. **Кросс-валидация**: Реализована кросс-валидация для всех моделей с использованием `cross_val_score`.\n",
    "4. **Интерпретация результатов**: Добавление вывода отчета о классификации для оценки метрик.\n",
    "5. **Сохранение модели**: Модели сохраняются с помощью `joblib`.\n",
    "\n",
    "Если нужно внести дополнительные изменения или улучшения, дай знать!\n",
    "\n",
    "\n",
    "2\n",
    "> PulseGPT - AI Assistant:\n",
    "Давайте более подробно рассмотрим, что делает обработка IQR (межквартильный размах) в вашем коде, \n",
    "а также предложим возможные улучшения.\n",
    "\n",
    "### Что делает код\n",
    "\n",
    "Функция `iqr_remove` выполняет следующие действия:\n",
    "\n",
    "1. **Получение числовых столбцов**:\n",
    "   - Если аргумент `columns` не задан, функция выбирает все числовые столбцы из DataFrame.\n",
    "\n",
    "2. **Копирование DataFrame**:\n",
    "   - Создается копия исходного DataFrame `df_clean`, чтобы сохранить оригинальные данные нетронутыми.\n",
    "\n",
    "3. **Расчет квартилей и IQR**:\n",
    "   - Для каждого столбца вычисляются первый (Q1) и третий (Q3) квартиль, а также IQR (межквартильный размах) как `IQR = Q3 - Q1`.\n",
    "\n",
    "4. **Определение границ**:\n",
    "   - Устанавливаются нижняя и верхняя границы для определения выбросов:\n",
    "     - `lower_bound = Q1 - threshold * IQR`\n",
    "     - `upper_bound = Q3 + threshold * IQR`\n",
    "   - Значение `threshold` по умолчанию равно 3, что означает, что все значения ниже `Q1 - 3 * IQR` и выше `Q3 + 3 * IQR` будут считаться выбросами.\n",
    "\n",
    "5. **Фильтрация данных**:\n",
    "   - Из DataFrame `df_clean` удаляются все строки, которые имеют значения за пределами установленных границ.\n",
    "\n",
    "6. **Возврат очищенного DataFrame**:\n",
    "   - Функция возвращает очищенный DataFrame без выбросов.\n",
    "\n",
    "### Пример использования\n",
    "\n",
    "Код ниже выполняет вышеописанную функцию для каждого DataFrame в массиве `arr` и выводит количество строк до и после удаления аномалий:\n",
    "\n",
    "```python\n",
    "for i, elem in enumerate(arr):\n",
    "    cleaned = iqr_remove(elem)\n",
    "    print(f\"{names_df[i]} до удаления аномалий: {elem.shape[0]} строк, {elem.shape[1]} столбцов\")\n",
    "    print(f\"{names_df[i]} после удаления аномалий: {cleaned.shape[0]} строк, {cleaned.shape[1]} столбцов\")\n",
    "    cleaned.to_csv(f'df/_{names_df[i]}_updt.csv', index=False)\n",
    "    print(\"Данные успешно сохранены.\")\n",
    "    perenos()\n",
    "```\n",
    "\n",
    "### Возможные улучшения\n",
    "\n",
    "1. **Гибкость порога**:\n",
    "   - Позвольте пользователю задавать значение `threshold` при вызове функции, чтобы адаптировать его под разные наборы данных.\n",
    "\n",
    "2. **Логирование выбросов**:\n",
    "   - Сохраните информацию о выбросах, чтобы можно было видеть, какие значения были удалены. Это может помочь в анализе и интерпретации данных.\n",
    "\n",
    "3. **Обработка пустых значений**:\n",
    "   - Добавьте обработку NaN значений перед вычислением квартилей, чтобы избежать ошибок.\n",
    "\n",
    "4. **Альтернативные методы для определения выбросов**:\n",
    "   - Рассмотрите возможность использования других методов обнаружения выбросов, таких как Z-оценка, для сравнения результатов.\n",
    "\n",
    "5. **Визуализация**:\n",
    "   - Добавьте возможность визуализировать данные до и после удаления выбросов с помощью boxplot, чтобы наглядно показать влияние очистки данных.\n",
    "\n",
    "6. **Обработка категориальных данных**:\n",
    "   - Если в вашем наборе данных есть категориальные переменные, рассмотрите возможность их обработки или преобразования в числовые значения, прежде чем применять IQR.\n",
    "\n",
    "### Пример улучшенного кода\n",
    "\n",
    "Вот обновленный код с учетом предложенных улучшений:\n",
    "\n",
    "def iqr_remove(df, columns=None, threshold=3):\n",
    "    if columns is None:\n",
    "        columns = df.select_dtypes(include=['number']).columns\n",
    "    \n",
    "    df_clean = df.copy()\n",
    "    anomalies = {}\n",
    "    \n",
    "    for col in columns:\n",
    "        # Проверка на NaN значения\n",
    "        if df[col].isnull().any():\n",
    "            df[col] = df[col].fillna(df[col].median())  # Заполнение медианой\n",
    "        \n",
    "        Q1 = df[col].quantile(0.25)  \n",
    "        Q3 = df[col].quantile(0.75)  \n",
    "        IQR = Q3 - Q1  \n",
    "        \n",
    "        lower_bound = Q1 - threshold * IQR  \n",
    "        upper_bound = Q3 + threshold * IQR\n",
    "        \n",
    "        # Сохранение выбросов\n",
    "        anomalies[col] = df[(df[col] < lower_bound) | (df[col] > upper_bound)]\n",
    "        \n",
    "        # Фильтрация данных\n",
    "        df_clean = df_clean[(df_clean[col] >= lower_bound) & (df_clean[col] <= upper_bound)]\n",
    "    \n",
    "    # Логирование выбросов\n",
    "    for col, anomaly_data in anomalies.items():\n",
    "        if not anomaly_data.empty:\n",
    "            print(f\"Выбросы в столбце {col}:\")\n",
    "            print(anomaly_data)\n",
    "\n",
    "    return df_clean\n",
    "\n",
    "for i, elem in enumerate(arr):\n",
    "    cleaned = iqr_re\n",
    "\n",
    "move(elem)\n",
    "    print(f\"{names_df[i]} до удаления аномалий: {elem.shape[0]} строк, {elem.shape[1]} столбцов\")\n",
    "    print(f\"{names_df[i]} после удаления аномалий: {cleaned.shape[0]} строк, {cleaned.shape[1]} столбцов\")\n",
    "    cleaned.to_csv(f'df/_{names_df[i]}_updt.csv', index=False)\n",
    "    print(\"Данные успешно сохранены.\")\n",
    "    perenos()\n",
    "\n",
    "Этот код добавляет обработку NaN значений и логирование выбросов, что делает обработку данных более прозрачной и информативной."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
